{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dgINPiqq8ccF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f549df87-c00e-4b96-d2f9-3142d26daa53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting azure-storage-blob\n",
            "  Downloading azure_storage_blob-12.19.1-py3-none-any.whl (394 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.5/394.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-core<2.0.0,>=1.28.0 (from azure-storage-blob)\n",
            "  Downloading azure_core-1.30.1-py3-none-any.whl (193 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.4/193.4 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob) (42.0.5)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob) (4.11.0)\n",
            "Collecting isodate>=0.6.1 (from azure-storage-blob)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob) (2.31.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.1.4->azure-storage-blob) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (2024.2.2)\n",
            "Installing collected packages: isodate, azure-core, azure-storage-blob\n",
            "Successfully installed azure-core-1.30.1 azure-storage-blob-12.19.1 isodate-0.6.1\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (14.0.2)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.25.2)\n",
            "Requirement already satisfied: psycopg2 in /usr/local/lib/python3.10/dist-packages (2.9.9)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.10/dist-packages (2.0.29)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install azure-storage-blob\n",
        "!pip install pyarrow\n",
        "!pip install psycopg2 sqlalchemy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import requests\n",
        "from io import StringIO\n",
        "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
        "from math import ceil\n",
        "import datetime\n",
        "import calendar\n",
        "from sqlalchemy import create_engine"
      ],
      "metadata": {
        "id": "X79eTrQMLQZ4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Azure Functions\n",
        "def azure_upload_blob(connect_str, container_name, blob_name, data):\n",
        "    blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
        "    blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
        "    blob_client.upload_blob(data, overwrite=True)\n",
        "    print(f\"Uploaded to Azure Blob: {blob_name}\")\n",
        "\n",
        "def azure_download_blob(connect_str, container_name, blob_name):\n",
        "    blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
        "    blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
        "    download_stream = blob_client.download_blob()\n",
        "    return download_stream.readall()\n"
      ],
      "metadata": {
        "id": "zwaLfzLKMLpm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path to your JSON configuration file\n",
        "config_file_path = 'config.json'\n",
        "\n",
        "# Load the JSON configuration file\n",
        "with open(config_file_path, 'r') as config_file:\n",
        "    config = json.load(config_file)\n",
        "\n",
        "# Print the configuration\n",
        "#Connection_STRING = config[\"connectionString\"]\n",
        "\n",
        "CONNECTION_STRING_AZURE_STORAGE = config[\"connectionString\"]\n",
        "CONTAINER_AZURE = 'motorvehiclecrash'\n",
        "\n",
        "# Initialize the BlobServiceClient\n",
        "blob_service_client = BlobServiceClient.from_connection_string(CONNECTION_STRING_AZURE_STORAGE)\n",
        "\n",
        "# Get the container client\n",
        "container_client = blob_service_client.get_container_client(CONTAINER_AZURE)\n",
        "\n",
        "mv_crash_df = pd.DataFrame()\n",
        "\n",
        "\n",
        "# List all blobs in the specified container\n",
        "blob_list = container_client.list_blobs()\n",
        "for blob in blob_list:\n",
        "    print(blob.name)\n",
        "    blob_client = container_client.get_blob_client(blob=blob.name)\n",
        "    blob_data = blob_client.download_blob()\n",
        "    blob_content = blob_data.readall().decode('utf-8')\n",
        "    df = pd.read_csv(StringIO(blob_content))\n",
        "    # Display the head of the DataFrame\n",
        "    print(df.shape)\n",
        "    # since I have only one csv, I am doing to do the following instructions\n",
        "    mv_crash_df = df.copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjXwXCihOFrH",
        "outputId": "adbe9be7-e3e5-4a24-c0bb-2f0eb7185b6e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "motorvehiclecrash.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-47f907e295d5>:30: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(StringIO(blob_content))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2082277, 29)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great success! The slightly modified ETL script was able to retrieve the csv dataset I had stored in the Azure Cloud. Now I can begin the transformations on the data. I begin first by removing the columns I wont need."
      ],
      "metadata": {
        "id": "j5UKByrxSWOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def week_of_month(dt):\n",
        "    first_day = dt.replace(day=1)\n",
        "    dom = dt.day\n",
        "    adjusted_dom = dom + first_day.weekday()\n",
        "    return int(ceil(adjusted_dom/7.0))\n",
        "\n",
        "def get_week_of_year(date_str):\n",
        "    \"\"\"\n",
        "    Calculate the ISO week number of the year for a given date.\n",
        "\n",
        "    Parameters:\n",
        "    date_str (str): A date string in the format 'YYYY-MM-DD'.\n",
        "\n",
        "    Returns:\n",
        "    int: ISO week number of the year.\n",
        "    \"\"\"\n",
        "    # Parse the input string to a datetime object\n",
        "    date = datetime.strptime(date_str, '%Y-%m-%d')\n",
        "\n",
        "    # Get the ISO calendar week number\n",
        "    week_of_year = date.isocalendar()[1]\n",
        "\n",
        "    return week_of_year"
      ],
      "metadata": {
        "id": "T8qOZM35MRmG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for null values in each column\n",
        "null_values = mv_crash_df.isnull().sum()\n",
        "\n",
        "# Display the count of null values in each column\n",
        "print(null_values)"
      ],
      "metadata": {
        "id": "yobxHL1LU6Ot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98a3ad51-9b3d-44bf-a0eb-a1ff6ca73722"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CRASH DATE                             0\n",
            "CRASH TIME                             0\n",
            "BOROUGH                           647881\n",
            "ZIP CODE                          648132\n",
            "LATITUDE                          234094\n",
            "LONGITUDE                         234094\n",
            "LOCATION                          234094\n",
            "ON STREET NAME                    442554\n",
            "CROSS STREET NAME                 787961\n",
            "OFF STREET NAME                  1732096\n",
            "NUMBER OF PERSONS INJURED             18\n",
            "NUMBER OF PERSONS KILLED              31\n",
            "NUMBER OF PEDESTRIANS INJURED          0\n",
            "NUMBER OF PEDESTRIANS KILLED           0\n",
            "NUMBER OF CYCLIST INJURED              0\n",
            "NUMBER OF CYCLIST KILLED               0\n",
            "NUMBER OF MOTORIST INJURED             0\n",
            "NUMBER OF MOTORIST KILLED              0\n",
            "CONTRIBUTING FACTOR VEHICLE 1       6845\n",
            "CONTRIBUTING FACTOR VEHICLE 2     323327\n",
            "CONTRIBUTING FACTOR VEHICLE 3    1933393\n",
            "CONTRIBUTING FACTOR VEHICLE 4    2048639\n",
            "CONTRIBUTING FACTOR VEHICLE 5    2073154\n",
            "COLLISION_ID                           0\n",
            "VEHICLE TYPE CODE 1                13808\n",
            "VEHICLE TYPE CODE 2               398959\n",
            "VEHICLE TYPE CODE 3              1938805\n",
            "VEHICLE TYPE CODE 4              2049808\n",
            "VEHICLE TYPE CODE 5              2073433\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned = mv_crash_df.copy()\n",
        "df_cleaned = mv_crash_df.drop(columns=['CONTRIBUTING FACTOR VEHICLE 3', 'CONTRIBUTING FACTOR VEHICLE 4', 'CONTRIBUTING FACTOR VEHICLE 5', 'VEHICLE TYPE CODE 3', 'VEHICLE TYPE CODE 4', 'VEHICLE TYPE CODE 5', 'OFF STREET NAME'])\n",
        "\n",
        "# Check for null values in each column\n",
        "null_values = df_cleaned.isnull().sum()\n",
        "\n",
        "# Display the count of null values in each column\n",
        "print(null_values)\n",
        "\n",
        "df_cleaned.shape"
      ],
      "metadata": {
        "id": "DSOpuHttU63V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f31a1277-075b-447d-95f0-7fc053e959ad"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CRASH DATE                            0\n",
            "CRASH TIME                            0\n",
            "BOROUGH                          647881\n",
            "ZIP CODE                         648132\n",
            "LATITUDE                         234094\n",
            "LONGITUDE                        234094\n",
            "LOCATION                         234094\n",
            "ON STREET NAME                   442554\n",
            "CROSS STREET NAME                787961\n",
            "NUMBER OF PERSONS INJURED            18\n",
            "NUMBER OF PERSONS KILLED             31\n",
            "NUMBER OF PEDESTRIANS INJURED         0\n",
            "NUMBER OF PEDESTRIANS KILLED          0\n",
            "NUMBER OF CYCLIST INJURED             0\n",
            "NUMBER OF CYCLIST KILLED              0\n",
            "NUMBER OF MOTORIST INJURED            0\n",
            "NUMBER OF MOTORIST KILLED             0\n",
            "CONTRIBUTING FACTOR VEHICLE 1      6845\n",
            "CONTRIBUTING FACTOR VEHICLE 2    323327\n",
            "COLLISION_ID                          0\n",
            "VEHICLE TYPE CODE 1               13808\n",
            "VEHICLE TYPE CODE 2              398959\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2082277, 22)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before starting the cleaning of missing/null values, I had 2,082,277 rows of data."
      ],
      "metadata": {
        "id": "uZmomTaBz1fH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with any null values and refresh the index\n",
        "df_cleaned.dropna(inplace=True)\n",
        "df_cleaned.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Check for null values in each column\n",
        "null_values = df_cleaned.isnull().sum()\n",
        "print(null_values)\n",
        "\n",
        "df_cleaned.shape\n"
      ],
      "metadata": {
        "id": "h_04znygVCDt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a5579c6-02c2-483c-8ce1-340b2ff86bdb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CRASH DATE                       0\n",
            "CRASH TIME                       0\n",
            "BOROUGH                          0\n",
            "ZIP CODE                         0\n",
            "LATITUDE                         0\n",
            "LONGITUDE                        0\n",
            "LOCATION                         0\n",
            "ON STREET NAME                   0\n",
            "CROSS STREET NAME                0\n",
            "NUMBER OF PERSONS INJURED        0\n",
            "NUMBER OF PERSONS KILLED         0\n",
            "NUMBER OF PEDESTRIANS INJURED    0\n",
            "NUMBER OF PEDESTRIANS KILLED     0\n",
            "NUMBER OF CYCLIST INJURED        0\n",
            "NUMBER OF CYCLIST KILLED         0\n",
            "NUMBER OF MOTORIST INJURED       0\n",
            "NUMBER OF MOTORIST KILLED        0\n",
            "CONTRIBUTING FACTOR VEHICLE 1    0\n",
            "CONTRIBUTING FACTOR VEHICLE 2    0\n",
            "COLLISION_ID                     0\n",
            "VEHICLE TYPE CODE 1              0\n",
            "VEHICLE TYPE CODE 2              0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(893205, 22)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After I dropped the null values from all the columns, I was left with 893K+ rows of data. I converted the data type of the ZIP CODE column into an integer to utilize it when creating the Location Dimension."
      ],
      "metadata": {
        "id": "N4zK2kjkzpcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display any unique values in 'ZIP CODE' that might not be numeric or are placeholders\n",
        "print(\"Unique non-numeric or placeholder values in 'ZIP CODE':\", df_cleaned[pd.to_numeric(df_cleaned['ZIP CODE'], errors='coerce').isna()]['ZIP CODE'].unique())\n",
        "\n",
        "# Replace any non-numeric values with pd.NA\n",
        "df_cleaned['ZIP CODE'] = pd.to_numeric(df_cleaned['ZIP CODE'], errors='coerce')\n",
        "\n",
        "# Now drop these as they are not valid ZIP codes\n",
        "df_cleaned.dropna(subset=['ZIP CODE'], inplace=True)\n",
        "\n",
        "# Try converting 'ZIP CODE' to 'Int64' again\n",
        "df_cleaned['ZIP CODE'] = df_cleaned['ZIP CODE'].astype('Int64')\n",
        "\n",
        "# Display the updated DataFrame shape and data type of 'ZIP CODE'\n",
        "print(\"Updated DataFrame shape:\", df_cleaned.shape)\n",
        "print(\"Data type of 'ZIP CODE':\", df_cleaned['ZIP CODE'].dtype)\n",
        "\n",
        "df_cleaned['ZIP CODE'].head()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwBwZ_6byJYb",
        "outputId": "e2cbe63f-56bf-4167-f77e-6654b711bb49"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique non-numeric or placeholder values in 'ZIP CODE': ['     ']\n",
            "Updated DataFrame shape: (893166, 22)\n",
            "Data type of 'ZIP CODE': Int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    10017\n",
              "1    11413\n",
              "2    11434\n",
              "3    10463\n",
              "4    10301\n",
              "Name: ZIP CODE, dtype: Int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding out the start and end date of the remaining data\n",
        "min_date = df_cleaned['CRASH DATE'].min()\n",
        "max_date = df_cleaned['CRASH DATE'].max()\n",
        "\n",
        "print(\"Minimum date:\", min_date)\n",
        "print(\"Maximum date:\", max_date)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tV8AEuZgl1qJ",
        "outputId": "e46b599d-3758-4a2f-983c-595a765bb8e5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum date: 01/01/2013\n",
            "Maximum date: 12/31/2023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have now removed the null values and un-necessary columns from the data. I will proceed with creating the dimensions for my DW. Starting with the Contributing Factor Dimension:"
      ],
      "metadata": {
        "id": "0aMQ6NS0hqsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract unique values from both columns\n",
        "unique_factors_1 = df_cleaned['CONTRIBUTING FACTOR VEHICLE 1'].dropna().unique()\n",
        "unique_factors_2 = df_cleaned['CONTRIBUTING FACTOR VEHICLE 2'].dropna().unique()\n",
        "\n",
        "# Combine and deduplicate the unique values from both columns\n",
        "all_unique_factors = pd.Series(list(set(unique_factors_1) | set(unique_factors_2)))\n",
        "\n",
        "# Create a DataFrame with IDs and descriptions\n",
        "dim_contributing_factor = pd.DataFrame(all_unique_factors, columns=['contributing-factor-description'])\n",
        "\n",
        "# Adding an ID column assuming a simple sequential ID is acceptable\n",
        "dim_contributing_factor['contributing-factor-id'] = range(1, len(dim_contributing_factor) + 1)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(dim_contributing_factor)\n",
        "dim_contributing_factor.info()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-V2_STK9guue",
        "outputId": "751f96f2-ed8f-42a4-cc3b-0af56556a653"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      contributing-factor-description  contributing-factor-id\n",
            "0                                 Passing Too Closely                       1\n",
            "1                               Windshield Inadequate                       2\n",
            "2   Pedestrian/Bicyclist/Other Pedestrian Error/Co...                       3\n",
            "3                    Lane Marking Improper/Inadequate                       4\n",
            "4                              Other Lighting Defects                       5\n",
            "5                          Listening/Using Headphones                       6\n",
            "6                                   Vehicle Vandalism                       7\n",
            "7         Traffic Control Device Improper/Non-Working                       8\n",
            "8                             Prescription Medication                       9\n",
            "9                                  Lost Consciousness                      10\n",
            "10                              Accelerator Defective                      11\n",
            "11                                                 80                      12\n",
            "12                             Cell Phone (hand-held)                      13\n",
            "13                                            Texting                      14\n",
            "14                             Cell Phone (hand-Held)                      15\n",
            "15               Reaction to Other Uninvolved Vehicle                      16\n",
            "16                              Following Too Closely                      17\n",
            "17                            Other Electronic Device                      18\n",
            "18                                             Illnes                      19\n",
            "19                                    Other Vehicular                      20\n",
            "20                                   Brakes Defective                      21\n",
            "21                                Physical Disability                      22\n",
            "22                               Unsafe Lane Changing                      23\n",
            "23                       Aggressive Driving/Road Rage                      24\n",
            "24                                        Unspecified                      25\n",
            "25                                 Turning Improperly                      26\n",
            "26                         Driverless/Runaway Vehicle                      27\n",
            "27                                     Tinted Windows                      28\n",
            "28                                    Fatigued/Drowsy                      29\n",
            "29                                            Illness                      30\n",
            "30                                              Glare                      31\n",
            "31                              Passenger Distraction                      32\n",
            "32                                    Drugs (Illegal)                      33\n",
            "33                                    Drugs (illegal)                      34\n",
            "34                                  Oversized Vehicle                      35\n",
            "35                               Headlights Defective                      36\n",
            "36                              Failure to Keep Right                      37\n",
            "37                     Reaction to Uninvolved Vehicle                      38\n",
            "38                                        Fell Asleep                      39\n",
            "39                                 Obstruction/Debris                      40\n",
            "40                       Shoulders Defective/Improper                      41\n",
            "41                      Failure to Yield Right-of-Way                      42\n",
            "42                     Driver Inattention/Distraction                      43\n",
            "43                                Alcohol Involvement                      44\n",
            "44                                 Pavement Defective                      45\n",
            "45                                  Pavement Slippery                      46\n",
            "46                            Tire Failure/Inadequate                      47\n",
            "47                        Traffic Control Disregarded                      48\n",
            "48                                   Backing Unsafely                      49\n",
            "49                            Cell Phone (hands-free)                      50\n",
            "50                                       Unsafe Speed                      51\n",
            "51                                Tow Hitch Defective                      52\n",
            "52                            Outside Car Distraction                      53\n",
            "53                                   Steering Failure                      54\n",
            "54                                     Animals Action                      55\n",
            "55                            View Obstructed/Limited                      56\n",
            "56                                 Eating or Drinking                      57\n",
            "57                     Passing or Lane Usage Improper                      58\n",
            "58                                Driver Inexperience                      59\n",
            "59                   Using On Board Navigation Device                      60\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 60 entries, 0 to 59\n",
            "Data columns (total 2 columns):\n",
            " #   Column                           Non-Null Count  Dtype \n",
            "---  ------                           --------------  ----- \n",
            " 0   contributing-factor-description  60 non-null     object\n",
            " 1   contributing-factor-id           60 non-null     int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 1.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, I will create the vehicle Dimension\n"
      ],
      "metadata": {
        "id": "xHEzYUHpiO0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract unique values from both vehicle type columns\n",
        "unique_vehicle_types_1 = df_cleaned['VEHICLE TYPE CODE 1'].unique()\n",
        "unique_vehicle_types_2 = df_cleaned['VEHICLE TYPE CODE 2'].unique()\n",
        "\n",
        "# Combine and deduplicate the unique values from both columns\n",
        "all_unique_vehicle_types = pd.Series(list(set(unique_vehicle_types_1) | set(unique_vehicle_types_2)))\n",
        "\n",
        "# Create a DataFrame with IDs and descriptions\n",
        "vehicle_type_df = pd.DataFrame(all_unique_vehicle_types, columns=['vehicle-type-description'])\n",
        "\n",
        "# Adding an ID column assuming a simple sequential ID is acceptable\n",
        "vehicle_type_df['vehicle-id'] = range(1, len(vehicle_type_df) + 1)\n",
        "dim_vehicle = vehicle_type_df\n",
        "\n",
        "# Display the DataFrame to verify\n",
        "print(dim_vehicle)\n",
        "dim_vehicle.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo7ze2JuiRr5",
        "outputId": "07a4728b-28ee-436e-a11f-9526e8bc8e6d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           vehicle-type-description  vehicle-id\n",
            "0                             inter           1\n",
            "1     SPORT UTILITY / STATION WAGON           2\n",
            "2                           utility           3\n",
            "3                             GATOR           4\n",
            "4                             Small           5\n",
            "...                             ...         ...\n",
            "1299                          EBIKE        1300\n",
            "1300                          bulld        1301\n",
            "1301                        Go kart        1302\n",
            "1302                       DELIVERY        1303\n",
            "1303                           f550        1304\n",
            "\n",
            "[1304 rows x 2 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1304 entries, 0 to 1303\n",
            "Data columns (total 2 columns):\n",
            " #   Column                    Non-Null Count  Dtype \n",
            "---  ------                    --------------  ----- \n",
            " 0   vehicle-type-description  1304 non-null   object\n",
            " 1   vehicle-id                1304 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 20.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we create the Location Dimension. For this dimension, I tried adding an attribute called neighbourhood which I intended to infer from the location co-ordinates. However, the code to retrieve the neighbourhood of each row took too long to run. ChatGPT estimated it would take approximately 10.3 days to complete."
      ],
      "metadata": {
        "id": "vi4spLbznpjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select necessary columns and ensure no rows with missing latitude or longitude\n",
        "df_location = df_cleaned[['BOROUGH', 'ZIP CODE', 'LATITUDE', 'LONGITUDE', 'LOCATION', 'ON STREET NAME', 'CROSS STREET NAME']].dropna(subset=['LATITUDE', 'LONGITUDE'])\n",
        "\n",
        "# Rename 'ZIP CODE' to 'zipcode' before creating the unique_zip_codes DataFrame\n",
        "df_location.rename(columns={'ZIP CODE': 'zipcode'}, inplace=True)\n",
        "\n",
        "# Extract unique ZIP codes and map them to a new ID column\n",
        "unique_zip_codes = pd.DataFrame(df_location['zipcode'].unique(), columns=['zipcode'])\n",
        "unique_zip_codes['location_ID'] = range(1, len(unique_zip_codes) + 1)\n",
        "\n",
        "# Merge unique ZIP codes back to df_location to assign location_ID based on 'zipcode'\n",
        "dim_location = pd.merge(df_location, unique_zip_codes, how='left', on='zipcode')\n",
        "\n",
        "# Optionally combine LATITUDE and LONGITUDE into 'location_coordinates' if needed\n",
        "dim_location['location-coordinates'] = dim_location['LATITUDE'].astype(str) + ', ' + dim_location['LONGITUDE'].astype(str)\n",
        "\n",
        "# Rename columns to match SQL table definition\n",
        "dim_location.rename(columns={\n",
        "    'BOROUGH': 'borough',\n",
        "    'LATITUDE': 'latitude',\n",
        "    'LONGITUDE': 'longitude',\n",
        "    'LOCATION': 'location_coordinates',\n",
        "    'ON STREET NAME': 'on-street-name',\n",
        "    'CROSS STREET NAME': 'cross-street-name'\n",
        "}, inplace=True)\n",
        "\n",
        "# Display the DataFrame to verify\n",
        "print(dim_location)\n",
        "dim_location.info()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2JdAu6moYe4",
        "outputId": "459efe3c-62f0-4a71-97a5-ba37531930fb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              borough  zipcode   latitude  longitude     location_coordinates  \\\n",
            "0           MANHATTAN    10017  40.751440 -73.973970    (40.75144, -73.97397)   \n",
            "1              QUEENS    11413  40.675884 -73.755770   (40.675884, -73.75577)   \n",
            "2              QUEENS    11434  40.666840 -73.789410    (40.66684, -73.78941)   \n",
            "3               BRONX    10463  40.872620 -73.904686   (40.87262, -73.904686)   \n",
            "4       STATEN ISLAND    10301  40.631650 -74.087620    (40.63165, -74.08762)   \n",
            "...               ...      ...        ...        ...                      ...   \n",
            "893161       BROOKLYN    11215  40.672066 -73.990524  (40.672066, -73.990524)   \n",
            "893162         QUEENS    11373  40.731968 -73.884780   (40.731968, -73.88478)   \n",
            "893163  STATEN ISLAND    10306  40.570465 -74.109770   (40.570465, -74.10977)   \n",
            "893164         QUEENS    11366  40.720955 -73.809350   (40.720955, -73.80935)   \n",
            "893165       BROOKLYN    11203  40.655514 -73.927864  (40.655514, -73.927864)   \n",
            "\n",
            "               on-street-name  cross-street-name  location_ID  \\\n",
            "0                    3 AVENUE     EAST 43 STREET            1   \n",
            "1       SPRINGFIELD BOULEVARD    EAST GATE PLAZA            2   \n",
            "2        NORTH CONDUIT AVENUE         150 STREET            3   \n",
            "3       WEST KINGSBRIDGE ROAD       HEATH AVENUE            4   \n",
            "4           VICTORY BOULEVARD   WOODSTOCK AVENUE            5   \n",
            "...                       ...                ...          ...   \n",
            "893161               8 STREET           3 AVENUE          149   \n",
            "893162           GRAND AVENUE          80 STREET           20   \n",
            "893163          NEW DORP LANE    HYLAN BOULEVARD           48   \n",
            "893164              79 AVENUE  PARSONS BOULEVARD           57   \n",
            "893165             LENOX ROAD     EAST 53 STREET           18   \n",
            "\n",
            "         location-coordinates  \n",
            "0         40.75144, -73.97397  \n",
            "1        40.675884, -73.75577  \n",
            "2         40.66684, -73.78941  \n",
            "3        40.87262, -73.904686  \n",
            "4         40.63165, -74.08762  \n",
            "...                       ...  \n",
            "893161  40.672066, -73.990524  \n",
            "893162   40.731968, -73.88478  \n",
            "893163   40.570465, -74.10977  \n",
            "893164   40.720955, -73.80935  \n",
            "893165  40.655514, -73.927864  \n",
            "\n",
            "[893166 rows x 9 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 893166 entries, 0 to 893165\n",
            "Data columns (total 9 columns):\n",
            " #   Column                Non-Null Count   Dtype  \n",
            "---  ------                --------------   -----  \n",
            " 0   borough               893166 non-null  object \n",
            " 1   zipcode               893166 non-null  Int64  \n",
            " 2   latitude              893166 non-null  float64\n",
            " 3   longitude             893166 non-null  float64\n",
            " 4   location_coordinates  893166 non-null  object \n",
            " 5   on-street-name        893166 non-null  object \n",
            " 6   cross-street-name     893166 non-null  object \n",
            " 7   location_ID           893166 non-null  int64  \n",
            " 8   location-coordinates  893166 non-null  object \n",
            "dtypes: Int64(1), float64(2), int64(1), object(5)\n",
            "memory usage: 62.2+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we create the date dimension."
      ],
      "metadata": {
        "id": "3tVbhBRh32Vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def time_of_day_bucket(hour):\n",
        "    \"\"\" Categorize time into buckets based on hour.\"\"\"\n",
        "    if 0 <= hour < 4:\n",
        "        return 'Late Night'\n",
        "    elif 4 <= hour < 8:\n",
        "        return 'Early Morning'\n",
        "    elif 8 <= hour < 12:\n",
        "        return 'Morning'\n",
        "    elif 12 <= hour < 16:\n",
        "        return 'Afternoon'\n",
        "    elif 16 <= hour < 20:\n",
        "        return 'Evening'\n",
        "    else:\n",
        "        return 'Night'\n",
        "\n",
        "# Convert and create necessary time columns\n",
        "df_cleaned['crash-time-stamp'] = pd.to_datetime(df_cleaned['CRASH DATE'].astype(str) + ' ' + df_cleaned['CRASH TIME'].astype(str))\n",
        "df_cleaned['CRASH DATE'] = pd.to_datetime(df_cleaned['CRASH DATE'])\n",
        "\n",
        "# Creating 'date-id' in df_cleaned\n",
        "df_cleaned['date-id'] = df_cleaned['crash-time-stamp'].dt.strftime('%Y%m%d%H%M')\n",
        "\n",
        "# Extract unique date-ids and associated rows\n",
        "unique_dates = df_cleaned.drop_duplicates(subset='date-id')\n",
        "\n",
        "# Initialize date_dimension using unique_dates\n",
        "date_dimension = pd.DataFrame({\n",
        "    'date-id': unique_dates['date-id'],\n",
        "    'crash-date': unique_dates['CRASH DATE'],\n",
        "    'crash-time': unique_dates['crash-time-stamp'],\n",
        "    'hour': unique_dates['crash-time-stamp'].dt.hour,\n",
        "    'am/pm-flag': unique_dates['crash-time-stamp'].dt.strftime('%p'),\n",
        "    'time-of-day-bucket': unique_dates['crash-time-stamp'].dt.hour.apply(time_of_day_bucket),\n",
        "    'date-iso-format': unique_dates['CRASH DATE'].apply(lambda x: x.isoformat()),\n",
        "    'year-number': unique_dates['CRASH DATE'].dt.year,\n",
        "    'quarter': unique_dates['CRASH DATE'].dt.quarter,\n",
        "    'month-number': unique_dates['CRASH DATE'].dt.month,\n",
        "    'day-number': unique_dates['CRASH DATE'].dt.day,\n",
        "    'month-name': unique_dates['CRASH DATE'].dt.strftime('%B'),\n",
        "    'day-name': unique_dates['CRASH DATE'].dt.strftime('%A'),\n",
        "    'week-of-the-year': unique_dates['CRASH DATE'].dt.isocalendar().week,\n",
        "    'week-of-the-month': unique_dates['CRASH DATE'].apply(week_of_month)\n",
        "})\n",
        "\n",
        "# Display the date_dimension DataFrame\n",
        "print(date_dimension)\n",
        "date_dimension.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XO86TKSBnsOw",
        "outputId": "52e1f631-9e85-46b2-eba2-cbd21c008c47"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             date-id crash-date          crash-time  hour am/pm-flag  \\\n",
            "0       202112141458 2021-12-14 2021-12-14 14:58:00    14         PM   \n",
            "1       202112141650 2021-12-14 2021-12-14 16:50:00    16         PM   \n",
            "2       202112142310 2021-12-14 2021-12-14 23:10:00    23         PM   \n",
            "3       202112111943 2021-12-11 2021-12-11 19:43:00    19         PM   \n",
            "4       202112131740 2021-12-13 2021-12-13 17:40:00    17         PM   \n",
            "...              ...        ...                 ...   ...        ...   \n",
            "893199  202404190727 2024-04-19 2024-04-19 07:27:00     7         AM   \n",
            "893200  202404080840 2024-04-08 2024-04-08 08:40:00     8         AM   \n",
            "893202  202404181425 2024-04-18 2024-04-18 14:25:00    14         PM   \n",
            "893203  202404181515 2024-04-18 2024-04-18 15:15:00    15         PM   \n",
            "893204  202404180640 2024-04-18 2024-04-18 06:40:00     6         AM   \n",
            "\n",
            "       time-of-day-bucket      date-iso-format  year-number  quarter  \\\n",
            "0               Afternoon  2021-12-14T00:00:00         2021        4   \n",
            "1                 Evening  2021-12-14T00:00:00         2021        4   \n",
            "2                   Night  2021-12-14T00:00:00         2021        4   \n",
            "3                 Evening  2021-12-11T00:00:00         2021        4   \n",
            "4                 Evening  2021-12-13T00:00:00         2021        4   \n",
            "...                   ...                  ...          ...      ...   \n",
            "893199      Early Morning  2024-04-19T00:00:00         2024        2   \n",
            "893200            Morning  2024-04-08T00:00:00         2024        2   \n",
            "893202          Afternoon  2024-04-18T00:00:00         2024        2   \n",
            "893203          Afternoon  2024-04-18T00:00:00         2024        2   \n",
            "893204      Early Morning  2024-04-18T00:00:00         2024        2   \n",
            "\n",
            "        month-number  day-number month-name  day-name  week-of-the-year  \\\n",
            "0                 12          14   December   Tuesday                50   \n",
            "1                 12          14   December   Tuesday                50   \n",
            "2                 12          14   December   Tuesday                50   \n",
            "3                 12          11   December  Saturday                49   \n",
            "4                 12          13   December    Monday                50   \n",
            "...              ...         ...        ...       ...               ...   \n",
            "893199             4          19      April    Friday                16   \n",
            "893200             4           8      April    Monday                15   \n",
            "893202             4          18      April  Thursday                16   \n",
            "893203             4          18      April  Thursday                16   \n",
            "893204             4          18      April  Thursday                16   \n",
            "\n",
            "        week-of-the-month  \n",
            "0                       3  \n",
            "1                       3  \n",
            "2                       3  \n",
            "3                       2  \n",
            "4                       3  \n",
            "...                   ...  \n",
            "893199                  3  \n",
            "893200                  2  \n",
            "893202                  3  \n",
            "893203                  3  \n",
            "893204                  3  \n",
            "\n",
            "[603312 rows x 15 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 603312 entries, 0 to 893204\n",
            "Data columns (total 15 columns):\n",
            " #   Column              Non-Null Count   Dtype         \n",
            "---  ------              --------------   -----         \n",
            " 0   date-id             603312 non-null  object        \n",
            " 1   crash-date          603312 non-null  datetime64[ns]\n",
            " 2   crash-time          603312 non-null  datetime64[ns]\n",
            " 3   hour                603312 non-null  int32         \n",
            " 4   am/pm-flag          603312 non-null  object        \n",
            " 5   time-of-day-bucket  603312 non-null  object        \n",
            " 6   date-iso-format     603312 non-null  object        \n",
            " 7   year-number         603312 non-null  int32         \n",
            " 8   quarter             603312 non-null  int32         \n",
            " 9   month-number        603312 non-null  int32         \n",
            " 10  day-number          603312 non-null  int32         \n",
            " 11  month-name          603312 non-null  object        \n",
            " 12  day-name            603312 non-null  object        \n",
            " 13  week-of-the-year    603312 non-null  UInt32        \n",
            " 14  week-of-the-month   603312 non-null  int64         \n",
            "dtypes: UInt32(1), datetime64[ns](2), int32(5), int64(1), object(6)\n",
            "memory usage: 60.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will create the Fact table"
      ],
      "metadata": {
        "id": "JemyMpoL7z4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create mapping dictionaries from the dimension DataFrames\n",
        "factor_id_map = dim_contributing_factor.set_index('contributing-factor-description')['contributing-factor-id'].to_dict()\n",
        "vehicle_type_map = dim_vehicle.set_index('vehicle-type-description')['vehicle-id'].to_dict()\n",
        "location_id_map = dim_location.set_index('zipcode')['location_ID'].to_dict()\n",
        "date_type_map = date_dimension.set_index('crash-time')['date-id'].to_dict()\n",
        "\n",
        "\n",
        "# Map contributing factor descriptions to IDs in df_cleaned\n",
        "df_cleaned['contributing-factor-id'] = df_cleaned['CONTRIBUTING FACTOR VEHICLE 1'].map(factor_id_map)\n",
        "\n",
        "# Map vehicle type descriptions to IDs in df_cleaned\n",
        "df_cleaned['vehicle-id'] = df_cleaned['VEHICLE TYPE CODE 1'].map(vehicle_type_map)\n",
        "\n",
        "# Map ZIP CODE to location IDs in df_cleaned\n",
        "df_cleaned['location-id'] = df_cleaned['ZIP CODE'].map(location_id_map)\n",
        "\n",
        "# Map crash-time-stamp to Date IDs in df_cleaned\n",
        "df_cleaned['date-id'] = df_cleaned['crash-time-stamp'].map(date_type_map)\n",
        "\n",
        "# Optionally, check how many IDs were successfully mapped and view the first few rows to confirm\n",
        "print(\"Number of mapped contributing factors:\", df_cleaned['contributing-factor-id'].notna().sum())\n",
        "print(\"Number of mapped vehicle types:\", df_cleaned['vehicle-id'].notna().sum())\n",
        "print(\"Number of mapped locations:\", df_cleaned['location-id'].notna().sum())\n",
        "print(\"Number of mapped dates:\", df_cleaned['date-id'].notna().sum())\n",
        "\n",
        "print(df_cleaned[['CONTRIBUTING FACTOR VEHICLE 1', 'contributing-factor-id', 'VEHICLE TYPE CODE 1', 'vehicle-id', 'ZIP CODE', 'location-id','crash-time-stamp','date-id']].head())"
      ],
      "metadata": {
        "id": "Je5qbfBhrMq3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2402a91b-2e35-4b7a-a4e1-049ba5fc1f1e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mapped contributing factors: 893166\n",
            "Number of mapped vehicle types: 893166\n",
            "Number of mapped locations: 893166\n",
            "Number of mapped dates: 893166\n",
            "    CONTRIBUTING FACTOR VEHICLE 1  contributing-factor-id  \\\n",
            "0             Passing Too Closely                       1   \n",
            "1              Turning Improperly                      26   \n",
            "2  Reaction to Uninvolved Vehicle                      38   \n",
            "3                     Unspecified                      25   \n",
            "4                     Unspecified                      25   \n",
            "\n",
            "                   VEHICLE TYPE CODE 1  vehicle-id  ZIP CODE  location-id  \\\n",
            "0                                Sedan         241     10017            1   \n",
            "1                                Sedan         241     11413            2   \n",
            "2                                Sedan         241     11434            3   \n",
            "3  Station Wagon/Sport Utility Vehicle         614     10463            4   \n",
            "4                                Sedan         241     10301            5   \n",
            "\n",
            "     crash-time-stamp       date-id  \n",
            "0 2021-12-14 14:58:00  202112141458  \n",
            "1 2021-12-14 16:50:00  202112141650  \n",
            "2 2021-12-14 23:10:00  202112142310  \n",
            "3 2021-12-11 19:43:00  202112111943  \n",
            "4 2021-12-13 17:40:00  202112131740  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.head()\n",
        "df_cleaned.shape"
      ],
      "metadata": {
        "id": "E5-rmYg44Qu-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96787d54-6d04-4ad7-8795-ad4ebd4ca12a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(893166, 27)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize fact_table with the primary key column\n",
        "fact_table = pd.DataFrame(df_cleaned['COLLISION_ID'].copy())\n",
        "fact_table.columns = ['collision_id']\n",
        "\n",
        "# Add number of persons killed\n",
        "fact_table['number-of-persons-killed'] = df_cleaned['NUMBER OF PERSONS KILLED'].copy()\n",
        "\n",
        "# Add number of pedestrians killed\n",
        "fact_table['number-of-pedestrians-killed'] = df_cleaned['NUMBER OF PEDESTRIANS KILLED'].copy()\n",
        "\n",
        "# Add number of cyclists killed\n",
        "fact_table['number-of-cyclists-killed'] = df_cleaned['NUMBER OF CYCLIST KILLED'].copy()\n",
        "\n",
        "# Add number of motorists killed\n",
        "fact_table['number-of-motorists-killed'] = df_cleaned['NUMBER OF MOTORIST KILLED'].copy()\n",
        "\n",
        "# Add number of persons injured\n",
        "fact_table['number-of-persons-injured'] = df_cleaned['NUMBER OF PERSONS INJURED'].copy()\n",
        "\n",
        "# Add number of pedestrians injured\n",
        "fact_table['number-of-pedestrians-injured'] = df_cleaned['NUMBER OF PEDESTRIANS INJURED'].copy()\n",
        "\n",
        "# Add number of cyclists injured\n",
        "fact_table['number-of-cyclists-injured'] = df_cleaned['NUMBER OF CYCLIST INJURED'].copy()\n",
        "\n",
        "# Add number of motorists injured\n",
        "fact_table['number-of-motorists-injured'] = df_cleaned['NUMBER OF MOTORIST INJURED'].copy()\n",
        "\n",
        "# Add vehicle-type-id (assuming it's correctly named and present)\n",
        "fact_table['vehicle-id'] = df_cleaned['vehicle-id'].copy()\n",
        "\n",
        "# Add location-id (if available and correctly named)\n",
        "fact_table['location-id'] = df_cleaned['location-id'].copy()\n",
        "\n",
        "# Add date-id\n",
        "fact_table['date-id'] = df_cleaned['date-id'].copy()\n",
        "\n",
        "# Add contributing-factor-id\n",
        "fact_table['contributing-factor-id'] = df_cleaned['contributing-factor-id'].copy()\n",
        "\n",
        "fact_table.head()"
      ],
      "metadata": {
        "id": "q5Y4BN9cu1tP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "83e877be-766a-4a60-924a-b8c770454b8b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   collision_id  number-of-persons-killed  number-of-pedestrians-killed  \\\n",
              "0       4486519                       0.0                             0   \n",
              "1       4487127                       0.0                             0   \n",
              "2       4486635                       0.0                             0   \n",
              "3       4487040                       0.0                             0   \n",
              "4       4487001                       0.0                             0   \n",
              "\n",
              "   number-of-cyclists-killed  number-of-motorists-killed  \\\n",
              "0                          0                           0   \n",
              "1                          0                           0   \n",
              "2                          0                           0   \n",
              "3                          0                           0   \n",
              "4                          0                           0   \n",
              "\n",
              "   number-of-persons-injured  number-of-pedestrians-injured  \\\n",
              "0                        0.0                              0   \n",
              "1                        0.0                              0   \n",
              "2                        2.0                              0   \n",
              "3                        1.0                              0   \n",
              "4                        1.0                              0   \n",
              "\n",
              "   number-of-cyclists-injured  number-of-motorists-injured  vehicle-id  \\\n",
              "0                           0                            0         241   \n",
              "1                           0                            0         241   \n",
              "2                           0                            2         241   \n",
              "3                           0                            1         614   \n",
              "4                           0                            1         241   \n",
              "\n",
              "   location-id       date-id  contributing-factor-id  \n",
              "0            1  202112141458                       1  \n",
              "1            2  202112141650                      26  \n",
              "2            3  202112142310                      38  \n",
              "3            4  202112111943                      25  \n",
              "4            5  202112131740                      25  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-280706b6-3503-4d6f-ae84-1949f260d28b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>collision_id</th>\n",
              "      <th>number-of-persons-killed</th>\n",
              "      <th>number-of-pedestrians-killed</th>\n",
              "      <th>number-of-cyclists-killed</th>\n",
              "      <th>number-of-motorists-killed</th>\n",
              "      <th>number-of-persons-injured</th>\n",
              "      <th>number-of-pedestrians-injured</th>\n",
              "      <th>number-of-cyclists-injured</th>\n",
              "      <th>number-of-motorists-injured</th>\n",
              "      <th>vehicle-id</th>\n",
              "      <th>location-id</th>\n",
              "      <th>date-id</th>\n",
              "      <th>contributing-factor-id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4486519</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>241</td>\n",
              "      <td>1</td>\n",
              "      <td>202112141458</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4487127</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>241</td>\n",
              "      <td>2</td>\n",
              "      <td>202112141650</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4486635</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>241</td>\n",
              "      <td>3</td>\n",
              "      <td>202112142310</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4487040</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>614</td>\n",
              "      <td>4</td>\n",
              "      <td>202112111943</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4487001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>241</td>\n",
              "      <td>5</td>\n",
              "      <td>202112131740</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-280706b6-3503-4d6f-ae84-1949f260d28b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-280706b6-3503-4d6f-ae84-1949f260d28b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-280706b6-3503-4d6f-ae84-1949f260d28b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f239d302-56f5-4d77-a898-801ed119bbc2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f239d302-56f5-4d77-a898-801ed119bbc2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f239d302-56f5-4d77-a898-801ed119bbc2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "fact_table"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The fact table has been created successfully. Looks like I need to change some column types to integers before I begin pushing the data into the Data Warehouse."
      ],
      "metadata": {
        "id": "WBRI99JGqfn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert columns to integer data type\n",
        "fact_table['number-of-persons-killed'] = fact_table['number-of-persons-killed'].astype(int)\n",
        "fact_table['number-of-persons-injured'] = fact_table['number-of-persons-injured'].astype(int)\n",
        "\n",
        "fact_table.head()\n",
        "\n",
        "fact_table.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkEQWDFHWXKZ",
        "outputId": "48a77ddf-c7f8-456d-d842-35db6aa23958"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(893166, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, I will begin pushing my tables to the DW. First we begin by creating the connection to the DW"
      ],
      "metadata": {
        "id": "jZePVv0pVzhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Database connection URL\n",
        "# Replace the placeholders with your actual database credentials\n",
        "pwd = 'Land4you!'\n",
        "database_url = f'postgresql://Salman:{pwd}@cis9440-hwdw-kss.postgres.database.azure.com/postgres'\n",
        "\n",
        "# Create a SQLAlchemy engine\n",
        "engine = create_engine(database_url)"
      ],
      "metadata": {
        "id": "hdAXKjD_VAQZ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding the data for my four dimensions, followed by the fact table"
      ],
      "metadata": {
        "id": "ComL4Z0rbW1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "date_dimension.to_sql('date_dimension', con=engine, if_exists='append', index=False)\n",
        "dim_vehicle.to_sql('dim_vehicle', con=engine, if_exists='append', index=False)\n",
        "dim_contributing_factor.to_sql('dim_contributing_factor', con=engine, if_exists='append', index=False)\n",
        "dim_location.to_sql('dim_location', con=engine, if_exists='append', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "284aJTYtV5KP",
        "outputId": "3cc03843-0b5b-42cf-dc08-eb310c061563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "166"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "date_dimension.to_sql('date_dimension', con=engine, if_exists='append', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6Z-enedtNTZ",
        "outputId": "152264f8-c493-4e17-dcdb-fb6ce51ff13a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "312"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fact_table.to_sql('fact_table', con=engine, if_exists='append', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9ZJtVJmW_ho",
        "outputId": "42591765-1ca2-4edd-8353-b4b78f9e6ced"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "166"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data went to tables under the public tab of DataGrip"
      ],
      "metadata": {
        "id": "2Uezq16dfY6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "date_dimension.to_csv(\"date_dimension.csv\",index=False)\n",
        "dim_location.to_csv(\"dim_location.csv\",index=False)\n",
        "dim_contributing_factor.to_csv(\"dim_contributing_factor\",index=False)\n",
        "dim_vehicle.to_csv(\"dim_vehicle.csv\",index=False)\n",
        "fact_table.to_csv(\"fact_table.csv\",index=False)"
      ],
      "metadata": {
        "id": "AtlWCKZabAa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "b8274b61-8ace-4964-f304-7bbab31bf218"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-a260fef6d351>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdate_dimension\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"date_dimension.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdim_location\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dim_location.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdim_contributing_factor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dim_contributing_factor\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdim_vehicle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dim_vehicle.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfact_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fact_table.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3770\u001b[0m         )\n\u001b[1;32m   3771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3772\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3773\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3774\u001b[0m             \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlineterminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m         )\n\u001b[0;32m-> 1186\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m             )\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_need_to_save_header\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstart_i\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslicer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_native_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_number_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         libwriters.write_csv_rows(\n\u001b[0m\u001b[1;32m    314\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/writers.pyx\u001b[0m in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generic Functions\n",
        "def create_string(length):\n",
        "    if isinstance(length, int) and length > 0:\n",
        "        result_string = \"(\" + \"?,\" * (length - 1) + \"?)\"\n",
        "        return result_string\n",
        "\n",
        "def insert_data(table_name, df):\n",
        "    conn = pyodbc.connect(connection_string)\n",
        "    cursor = conn.cursor()\n",
        "    result = create_string(len(df.columns))\n",
        "    # Insert data into the table\n",
        "    insert_query = f\"INSERT INTO {table_name} VALUES {result}\"\n",
        "    print(insert_query)\n",
        "    cursor.executemany(insert_query, df.values.tolist())\n",
        "    conn.commit()\n",
        "    conn.close()"
      ],
      "metadata": {
        "id": "udiFFZktfgGT"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}
